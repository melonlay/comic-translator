"""
Text Translator
æ–‡å­—ç¿»è­¯å™¨

ä½¿ç”¨Geminié€²è¡Œæ–‡å­—ç¿»è­¯ï¼Œæ”¯æ´æ­·å²ä¸Šä¸‹æ–‡
"""

import json
import re
import time
from typing import List, Dict, Any, Optional
from ..utils.gemini_client import GeminiClient
from pathlib import Path


class TextTranslator:
    """
    æ–‡å­—ç¿»è­¯å™¨
    Text Translator
    
    ä½¿ç”¨Geminié€²è¡Œæ™ºèƒ½ç¿»è­¯ï¼Œæ”¯æ´æ­·å²ä¸Šä¸‹æ–‡
    """
    
    def __init__(self, gemini_client: GeminiClient):
        """
        åˆå§‹åŒ–ç¿»è­¯å™¨
        
        Args:
            gemini_client: Geminiå®¢æˆ¶ç«¯å¯¦ä¾‹
        """
        self.gemini_client = gemini_client
        self.api_call_count = 0
        self.translation_cache = {}
        
        print("âœ… æ–‡å­—ç¿»è­¯å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def translate_texts_with_history(
        self, 
        texts: List[str], 
        terminology_dict: Dict[str, str] = None,
        translation_history: List[Dict[str, str]] = None,
        image_path: str = None
    ) -> Dict[str, Any]:
        """
        ç¿»è­¯æ–‡å­—åˆ—è¡¨ï¼ˆä½¿ç”¨æ­·å²ä¸Šä¸‹æ–‡å’Œåœ–ç‰‡åˆ†æï¼‰
        
        Args:
            texts: å¾…ç¿»è­¯çš„æ–‡å­—åˆ—è¡¨
            terminology_dict: å°ˆæœ‰åè©å­—å…¸
            translation_history: ç¿»è­¯æ­·å²ä¸Šä¸‹æ–‡
            image_path: åœ–ç‰‡è·¯å¾‘ï¼Œç”¨æ–¼è¦–è¦ºåˆ†æ
            
        Returns:
            Dict: ç¿»è­¯çµæœ
        """
        if not texts:
            return {'translated_texts': [], 'new_terminology': {}, 'success': False}
        
        print(f"ğŸŒ é–‹å§‹ç¿»è­¯ {len(texts)} å€‹æ–‡å­—...")
        if image_path:
            print(f"ğŸ“· ä½¿ç”¨åœ–ç‰‡åˆ†æ: {Path(image_path).name}")
        
        # ä½¿ç”¨structured outputé€²è¡Œç¿»è­¯
        response_schema = {
            "type": "object",
            "properties": {
                "translations": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "original": {"type": "string"},
                            "translated": {"type": "string"},
                            "text_direction": {
                                "type": "string",
                                "enum": ["horizontal", "vertical"],
                                "description": "æ–‡å­—æ’ç‰ˆæ–¹å‘ï¼šhorizontal(æ©«æ›¸)æˆ–vertical(ç›´æ›¸)"
                            },
                            "bubble_type": {
                                "type": "string", 
                                "enum": ["pure_white", "textured", "transparent"],
                                "description": "å°è©±æ¡†é¡å‹ï¼špure_white(ç´”ç™½)ã€textured(æœ‰ç´‹ç†/æ¼¸è®Š)æˆ–transparent(é€æ˜)"
                            },
                            "estimated_font_size": {
                                "type": "integer",
                                "description": "ä¼°è¨ˆçš„åŸå§‹å­—é«”å¤§å°(åƒç´ )"
                            }
                        },
                        "required": ["original", "translated", "text_direction", "bubble_type", "estimated_font_size"]
                    }
                },
                "new_terminology": {
                    "type": "array",
                    "description": "ç™¼ç¾çš„æ–°å°ˆæœ‰åè©",
                    "items": {
                        "type": "object",
                        "properties": {
                            "japanese": {"type": "string", "description": "æ—¥æ–‡åŸæ–‡"},
                            "chinese": {"type": "string", "description": "ä¸­æ–‡ç¿»è­¯"}
                        },
                        "required": ["japanese", "chinese"]
                    }
                }
            },
            "required": ["translations", "new_terminology"]
        }
        
        prompt = self._create_enhanced_translation_prompt(texts, terminology_dict, translation_history, image_path)
        
        try:
            # å¦‚æœæœ‰åœ–ç‰‡ï¼Œä½¿ç”¨åœ–ç‰‡åˆ†æåŠŸèƒ½
            if image_path and Path(image_path).exists():
                result = self.gemini_client.generate_structured_content_with_image(
                    prompt, image_path, response_schema
                )
                print("âœ… ä½¿ç”¨åœ–ç‰‡è¦–è¦ºåˆ†æé€²è¡Œç¿»è­¯")
            else:
                # æ²’æœ‰åœ–ç‰‡æ™‚ä½¿ç”¨ç´”æ–‡å­—åˆ†æ
                result = self.gemini_client.generate_structured_content(prompt, response_schema)
                print("âš ï¸ æœªæä¾›åœ–ç‰‡ï¼Œä½¿ç”¨ç´”æ–‡å­—åˆ†æ")
            
            translations = result.get('translations', [])
            new_terminology = result.get('new_terminology', [])
            
            # å°‡ new_terminology å¾æ•¸çµ„æ ¼å¼è½‰æ›ç‚ºå­—å…¸æ ¼å¼
            terminology_dict = {}
            for term in new_terminology:
                if isinstance(term, dict) and 'japanese' in term and 'chinese' in term:
                    terminology_dict[term['japanese']] = term['chinese']
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            translated_texts = []
            for translation in translations:
                translated_texts.append({
                    'original': translation['original'],
                    'translated': translation['translated'],
                    'text_direction': translation['text_direction'],
                    'bubble_type': translation['bubble_type'],
                    'estimated_font_size': translation['estimated_font_size']
                })
            
            print(f"âœ… ç¿»è­¯å®Œæˆ: {len(translated_texts)} å€‹æ–‡å­—")
            
            return {
                'translated_texts': translated_texts,
                'new_terminology': terminology_dict,
                'success': True
            }
            
        except Exception as e:
            print(f"âš ï¸ Structuredç¿»è­¯å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ³•: {e}")
            # å›é€€åˆ°èˆŠæ–¹æ³•
            return self._fallback_translation(texts, terminology_dict, translation_history, image_path)
    
    def _create_enhanced_translation_prompt(self, texts: List[str], terminology_dict: Dict[str, str], 
                                          translation_history: List[Dict[str, str]] = None, 
                                          image_path: str = None) -> str:
        """
        å‰µå»ºå¢å¼·çš„ç¿»è­¯æç¤ºè©ï¼ˆåŒ…å«æ’ç‰ˆå’Œå°è©±æ¡†åˆ†æï¼‰
        
        Args:
            texts: å¾…ç¿»è­¯æ–‡å­—
            terminology_dict: å°ˆæœ‰åè©å­—å…¸
            translation_history: ç¿»è­¯æ­·å²
            image_path: åœ–ç‰‡è·¯å¾‘
            
        Returns:
            str: ç¿»è­¯æç¤ºè©
        """
        # æº–å‚™æ­·å²ä¸Šä¸‹æ–‡
        history_context = ""
        if translation_history and len(translation_history) > 0:
            recent_history = translation_history[-10:]  # æœ€è¿‘10æ¢
            history_context = "\n\nå‰æ–‡ç¿»è­¯åƒè€ƒï¼š\n"
            for i, item in enumerate(recent_history, 1):
                history_context += f"{i}. ã€Œ{item.get('original', '')}ã€â†’ã€Œ{item.get('translated', '')}ã€\n"
        
        # æº–å‚™å°ˆæœ‰åè©
        terminology_context = ""
        if terminology_dict:
            terminology_context = "\n\nå°ˆæœ‰åè©å­—å…¸ï¼ˆå¿…é ˆä½¿ç”¨ä¸€è‡´ç¿»è­¯ï¼‰ï¼š\n"
            for jp, cn in terminology_dict.items():
                terminology_context += f"ã€Œ{jp}ã€â†’ã€Œ{cn}ã€\n"
        
        # æ ¹æ“šæ˜¯å¦æœ‰åœ–ç‰‡èª¿æ•´æç¤ºè©
        if image_path:
            visual_analysis_instruction = """
**é‡è¦ï¼šè«‹åŒæ™‚åˆ†ææä¾›çš„æ¼«ç•«åœ–ç‰‡ï¼Œé€²è¡ŒOCRæ ¡æ­£å’Œè¦–è¦ºç‰¹å¾µåˆ†æ**

åœ–ç‰‡åˆ†æè¦æ±‚ï¼š
1. **OCR æ ¡æ­£åŠŸèƒ½**ï¼š
   - å°‡æä¾›çš„ OCR è­˜åˆ¥æ–‡å­—èˆ‡åœ–ç‰‡ä¸­çš„å¯¦éš›æ–‡å­—é€²è¡Œå°æ¯”
   - è­˜åˆ¥å¯èƒ½çš„ OCR éŒ¯èª¤ï¼ˆå¦‚ç›¸ä¼¼å­—ç¬¦æ··æ·†ã€ç¼ºå­—ã€å¤šå­—ç­‰ï¼‰
   - æ ¡æ­£éŒ¯èª¤çš„æ–‡å­—ï¼Œç¢ºä¿æº–ç¢ºç†è§£åŸæ–‡å«ç¾©
   - å¸¸è¦‹ OCR éŒ¯èª¤ç¤ºä¾‹ï¼š
     * ã€Œãƒ­ã€èˆ‡ã€Œå£ã€ã€ã€ŒåŠ›ã€èˆ‡ã€Œåˆ€ã€ã€ã€Œãƒ¼ã€èˆ‡ã€Œä¸€ã€çš„æ··æ·†
     * æ‰‹å¯«å­—é«”å¯èƒ½å°è‡´çš„è­˜åˆ¥éŒ¯èª¤
     * ç‰¹æ®Šå­—é«”ã€æ–œé«”æ–‡å­—çš„è­˜åˆ¥å•é¡Œ

2. **å¯¦éš›è§€å¯Ÿæ–‡å­—æ’ç‰ˆ**ï¼š
   - ä»”ç´°è§€å¯Ÿæ¯å€‹æ–‡å­—å€åŸŸçš„æ–‡å­—æ˜¯æ©«å‘æ’åˆ—é‚„æ˜¯ç¸±å‘æ’åˆ—
   - horizontalï¼šæ–‡å­—å¾å·¦åˆ°å³æ°´å¹³æ’åˆ—
   - verticalï¼šæ–‡å­—å¾ä¸Šåˆ°ä¸‹å‚ç›´æ’åˆ—

3. **å°è©±æ¡†èƒŒæ™¯åˆ†æ**ï¼š
   - pure_whiteï¼šç´”ç™½è‰²èƒŒæ™¯ï¼Œé‚Šç·£æ¸…æ™°çš„å°è©±æ¡†
   - texturedï¼šæœ‰æ¼¸è®Šã€é™°å½±ã€ç´‹ç†çš„å°è©±æ¡†èƒŒæ™¯
   - transparentï¼šé€æ˜æˆ–åŠé€æ˜çš„å°è©±æ¡†

4. **å­—é«”å¤§å°ä¼°è¨ˆ**ï¼š
   - æ ¹æ“šåœ–ç‰‡ä¸­æ–‡å­—çš„å¯¦éš›å¤§å°ä¼°è¨ˆåƒç´ å€¼ï¼ˆé€šå¸¸8-40åƒç´ ï¼‰
   - è€ƒæ…®æ–‡å­—èˆ‡å°è©±æ¡†çš„æ¯”ä¾‹é—œä¿‚

**é‡è¦ï¼šå¦‚æœç™¼ç¾ OCR éŒ¯èª¤ï¼Œè«‹åœ¨ç¿»è­¯çµæœä¸­ä½¿ç”¨æ ¡æ­£å¾Œçš„æ­£ç¢ºæ–‡å­—**"""
        else:
            visual_analysis_instruction = """
**æ³¨æ„ï¼šç”±æ–¼æ²’æœ‰æä¾›åœ–ç‰‡ï¼Œç„¡æ³•é€²è¡Œ OCR æ ¡æ­£ï¼Œè«‹æ ¹æ“šæ–‡å­—å…§å®¹å’Œå¸¸è¦‹æ¼«ç•«æ’ç‰ˆè¦å¾‹é€²è¡Œåˆ¤æ–·**

æ¨æ–·è¦å‰‡ï¼š
1. **æ–‡å­—æ’ç‰ˆæ–¹å‘**ï¼š
   - çŸ­å¥ã€å°è©±é€šå¸¸ç”¨ horizontal
   - é•·æ®µè½ã€æ—ç™½é€šå¸¸ç”¨ vertical
   
2. **å°è©±æ¡†é¡å‹**ï¼š
   - å°è©±æ–‡å­—é€šå¸¸ç”¨ pure_white
   - æ—ç™½ã€æ€è€ƒæ–‡å­—å¯èƒ½ç”¨ textured
   
3. **å­—é«”å¤§å°**ï¼š
   - å°è©±æ–‡å­—é€šå¸¸ 12-20 åƒç´ 
   - æ—ç™½æ–‡å­—é€šå¸¸ 10-16 åƒç´ """

        return f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æ–‡æ¼«ç•«ç¿»è­¯å°ˆå®¶å’Œ OCR æ ¡æ­£å°ˆå®¶ã€‚è«‹åˆ†ææä¾›çš„ OCR è­˜åˆ¥æ–‡å­—ï¼Œæ ¡æ­£å¯èƒ½çš„éŒ¯èª¤ï¼Œç„¶å¾Œå°‡æ­£ç¢ºçš„æ—¥æ–‡ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚

{visual_analysis_instruction}

ç¿»è­¯å’Œæ ¡æ­£åŸå‰‡ï¼š
- **é¦–è¦ä»»å‹™**ï¼šå¦‚æœæä¾›äº†åœ–ç‰‡ï¼Œè«‹å…ˆæ ¡æ­£ OCR è­˜åˆ¥éŒ¯èª¤ï¼Œç¢ºä¿ç†è§£æ­£ç¢ºçš„åŸæ–‡
- ä¿æŒæ¼«ç•«å°è©±çš„è‡ªç„¶æ€§å’Œæµæš¢æ€§
- ç¶­æŒè§’è‰²çš„èªèª¿å’Œå€‹æ€§
- å°ˆæœ‰åè©å¿…é ˆä¿æŒä¸€è‡´æ€§
- è€ƒæ…®ä¸Šä¸‹æ–‡é€£è²«æ€§

å¾…è™•ç†çš„ OCR è­˜åˆ¥æ–‡å­—ï¼š
{json.dumps(texts, ensure_ascii=False, indent=2)}
{terminology_context}
{history_context}

è«‹ç‚ºæ¯å€‹æ–‡å­—æä¾›ï¼š
1. **æ ¡æ­£å¾Œçš„æ­£ç¢ºæ—¥æ–‡åŸæ–‡**ï¼ˆå¦‚æœ OCR æœ‰éŒ¯èª¤ï¼‰
2. æº–ç¢ºçš„ç¹é«”ä¸­æ–‡ç¿»è­¯
3. æ–‡å­—æ’ç‰ˆæ–¹å‘åˆ¤æ–·ï¼ˆhorizontal/verticalï¼‰
4. å°è©±æ¡†é¡å‹åˆ¤æ–·ï¼ˆpure_white/textured/transparentï¼‰
5. ä¼°è¨ˆçš„å­—é«”å¤§å°ï¼ˆåƒç´ å€¼ï¼‰
6. ç™¼ç¾çš„æ–°å°ˆæœ‰åè©

æ³¨æ„ï¼šåœ¨ "original" æ¬„ä½ä¸­è«‹æä¾›æ ¡æ­£å¾Œçš„æ­£ç¢ºæ—¥æ–‡ï¼Œè€Œä¸æ˜¯ OCR çš„éŒ¯èª¤è­˜åˆ¥çµæœã€‚

è¼¸å‡ºå¿…é ˆæ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"""
    
    def translate_texts(
        self, 
        texts: List[str], 
        terminology_dict: Dict[str, str] = None,
        image_path: str = None
    ) -> Dict[str, Any]:
        """
        ç¿»è­¯æ–‡å­—åˆ—è¡¨ï¼ˆä¸ä½¿ç”¨æ­·å²ä¸Šä¸‹æ–‡ï¼‰
        
        Args:
            texts: è¦ç¿»è­¯çš„æ–‡å­—åˆ—è¡¨
            terminology_dict: å°ˆæœ‰åè©å­—å…¸
            image_path: åœ–ç‰‡è·¯å¾‘ï¼Œç”¨æ–¼è¦–è¦ºåˆ†æ
            
        Returns:
            Dict: ç¿»è­¯çµæœ
        """
        return self.translate_texts_with_history(texts, terminology_dict, [], image_path)
    
    def _fallback_translation(self, texts: List[str], terminology_dict: Dict[str, str], 
                             translation_history: List[Dict[str, str]] = None, 
                             image_path: str = None) -> Dict[str, Any]:
        """
        å‚™ç”¨ç¿»è­¯æ–¹æ³•ï¼ˆæ”¯æ´åœ–ç‰‡ OCR æ ¡æ­£ï¼‰
        
        Args:
            texts: è¦ç¿»è­¯çš„æ–‡å­—åˆ—è¡¨
            terminology_dict: å°ˆæœ‰åè©å­—å…¸
            translation_history: ç¿»è­¯æ­·å²ä¸Šä¸‹æ–‡
            image_path: åœ–ç‰‡è·¯å¾‘ï¼Œç”¨æ–¼ OCR æ ¡æ­£
            
        Returns:
            Dict: ç¿»è­¯çµæœ
        """
        if not texts:
            return {
                'translated_texts': [],
                'new_terminology': [],
                'success': False
            }
        
        print(f"ğŸ”„ é–‹å§‹ç¿»è­¯ {len(texts)} å€‹æ–‡å­—")
        if translation_history:
            print(f"ğŸ“š ä½¿ç”¨ {len(translation_history)} æ¢æ­·å²ç¿»è­¯ä½œç‚ºä¸Šä¸‹æ–‡")
        if image_path:
            print(f"ğŸ“· ä½¿ç”¨åœ–ç‰‡é€²è¡Œ OCR æ ¡æ­£: {Path(image_path).name}")
        
        start_time = time.time()
        
        try:
            # æº–å‚™ç¿»è­¯æç¤ºè©ï¼ŒåŒ…å«æ­·å²ä¸Šä¸‹æ–‡
            prompt = self._prepare_translation_prompt_with_history(
                texts, terminology_dict or {}, translation_history or [], image_path
            )
            
            # å‘¼å«Gemini API
            self.api_call_count += 1
            print(f"ğŸ’° API å‘¼å« #{self.api_call_count} - æ¨¡å‹: {self.gemini_client.model_name}")
            
            # æ ¹æ“šæ˜¯å¦æœ‰åœ–ç‰‡é¸æ“‡ API æ–¹æ³•
            if image_path and Path(image_path).exists():
                response = self.gemini_client.generate_content_with_image(prompt, image_path)
                print("âœ… ä½¿ç”¨åœ–ç‰‡é€²è¡Œ OCR æ ¡æ­£ç¿»è­¯")
            else:
                response = self.gemini_client.generate_content(prompt)
                print("âš ï¸ ä½¿ç”¨ç´”æ–‡å­—ç¿»è­¯ï¼ˆç„¡ OCR æ ¡æ­£ï¼‰")
            
            if not response:
                print("âŒ API å›æ‡‰ç‚ºç©º")
                return {
                    'translated_texts': [],
                    'new_terminology': [],
                    'success': False,
                    'error': 'Empty API response'
                }
            
            # è§£æç¿»è­¯çµæœ
            result = self._parse_translation_response_with_terminology(response, texts)
            
            processing_time = time.time() - start_time
            
            print(f"âœ… ç¿»è­¯å®Œæˆï¼Œè€—æ™‚: {processing_time:.2f}ç§’")
            print(f"ğŸ“ æˆåŠŸç¿»è­¯: {len(result['translated_texts'])}/{len(texts)}")
            print(f"ğŸ†• ç™¼ç¾æ–°å°ˆæœ‰åè©: {len(result['new_terminology'])}")
            
            return {
                'translated_texts': result['translated_texts'],
                'new_terminology': result['new_terminology'],
                'success': True
            }
            
        except Exception as e:
            print(f"âŒ ç¿»è­¯éç¨‹å‡ºéŒ¯: {e}")
            return {
                'translated_texts': self._create_fallback_translations(texts),
                'new_terminology': {},
                'success': False,
                'error': str(e)
            }
    
    def _prepare_translation_prompt_with_history(
        self, 
        texts: List[str], 
        terminology_dict: Dict[str, str],
        translation_history: List[Dict[str, str]],
        image_path: str = None
    ) -> str:
        """
        æº–å‚™åŒ…å«æ­·å²ä¸Šä¸‹æ–‡çš„ç¿»è­¯æç¤ºè©ï¼ˆæ”¯æ´ OCR æ ¡æ­£ï¼‰
        
        Args:
            texts: è¦ç¿»è­¯çš„æ–‡å­—
            terminology_dict: å°ˆæœ‰åè©å­—å…¸
            translation_history: ç¿»è­¯æ­·å²
            image_path: åœ–ç‰‡è·¯å¾‘
            
        Returns:
            str: ç¿»è­¯æç¤ºè©
        """
        
        # æ ¹æ“šæ˜¯å¦æœ‰åœ–ç‰‡èª¿æ•´åŸºæœ¬æç¤ºè©
        if image_path:
            base_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ—¥æ–‡æ¼«ç•«ç¿»è­¯å¸«å’Œ OCR æ ¡æ­£å°ˆå®¶ï¼Œæ“…é•·å°‡æ—¥æ–‡æ¼«ç•«å°è©±ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚

**é‡è¦ï¼šOCR æ ¡æ­£åŠŸèƒ½**
è«‹é¦–å…ˆè§€å¯Ÿæä¾›çš„æ¼«ç•«åœ–ç‰‡ï¼Œå°æ¯” OCR è­˜åˆ¥çš„æ–‡å­—èˆ‡åœ–ç‰‡ä¸­çš„å¯¦éš›æ–‡å­—ï¼š
1. è­˜åˆ¥å¯èƒ½çš„ OCR éŒ¯èª¤ï¼ˆå¦‚ç›¸ä¼¼å­—ç¬¦æ··æ·†ã€ç¼ºå­—ã€å¤šå­—ç­‰ï¼‰
2. æ ¡æ­£éŒ¯èª¤çš„æ–‡å­—ï¼Œç¢ºä¿æº–ç¢ºç†è§£åŸæ–‡å«ç¾©
3. å¸¸è¦‹ OCR éŒ¯èª¤ï¼šã€Œãƒ­ã€èˆ‡ã€Œå£ã€ã€ã€ŒåŠ›ã€èˆ‡ã€Œåˆ€ã€ã€ã€Œãƒ¼ã€èˆ‡ã€Œä¸€ã€çš„æ··æ·†ç­‰

ç¿»è­¯åŸå‰‡ï¼š
1. **é¦–è¦ä»»å‹™**ï¼šæ ¡æ­£ OCR è­˜åˆ¥éŒ¯èª¤ï¼Œç¢ºä¿ç†è§£æ­£ç¢ºçš„åŸæ–‡
2. ä¿æŒæ¼«ç•«å°è©±çš„è‡ªç„¶èªèª¿å’Œæƒ…æ„Ÿ
3. ä½¿ç”¨å°ç£å¸¸ç”¨çš„ç¹é«”ä¸­æ–‡è¡¨é”æ–¹å¼
4. ä¿ç•™è§’è‰²çš„èªªè©±ç‰¹è‰²å’Œå€‹æ€§
5. é©ç•¶è™•ç†æ“¬è²è©å’Œæ„Ÿå˜†è©
6. ç¢ºä¿ç¿»è­¯ç¬¦åˆæ¼«ç•«çš„èªå¢ƒå’Œæ°›åœ
7. ç™¼ç¾ä¸¦æ¨™è¨˜æ–°çš„å°ˆæœ‰åè©ï¼ˆäººåã€åœ°åã€ç‰¹æ®Šè¡“èªç­‰ï¼‰

è¼¸å‡ºæ ¼å¼ï¼š
è«‹æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¼¸å‡ºï¼ˆæ³¨æ„ï¼šåœ¨ "original" æ¬„ä½ä¸­è«‹æä¾›æ ¡æ­£å¾Œçš„æ­£ç¢ºæ—¥æ–‡ï¼‰ï¼š
{
  "translated_texts": [
    {
      "original": "æ ¡æ­£å¾Œçš„æ­£ç¢ºæ—¥æ–‡åŸæ–‡",
      "translated": "ç¿»è­¯çµæœ"
    }
  ],
  "new_terminology": [
    {
      "japanese": "æ—¥æ–‡åŸæ–‡",
      "chinese": "ä¸­æ–‡ç¿»è­¯"
    }
  ]
}"""
        else:
            base_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ—¥æ–‡æ¼«ç•«ç¿»è­¯å¸«ï¼Œæ“…é•·å°‡æ—¥æ–‡æ¼«ç•«å°è©±ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚

ç¿»è­¯åŸå‰‡ï¼š
1. ä¿æŒæ¼«ç•«å°è©±çš„è‡ªç„¶èªèª¿å’Œæƒ…æ„Ÿ
2. ä½¿ç”¨å°ç£å¸¸ç”¨çš„ç¹é«”ä¸­æ–‡è¡¨é”æ–¹å¼
3. ä¿ç•™è§’è‰²çš„èªªè©±ç‰¹è‰²å’Œå€‹æ€§
4. é©ç•¶è™•ç†æ“¬è²è©å’Œæ„Ÿå˜†è©
5. ç¢ºä¿ç¿»è­¯ç¬¦åˆæ¼«ç•«çš„èªå¢ƒå’Œæ°›åœ
6. ç™¼ç¾ä¸¦æ¨™è¨˜æ–°çš„å°ˆæœ‰åè©ï¼ˆäººåã€åœ°åã€ç‰¹æ®Šè¡“èªç­‰ï¼‰

è¼¸å‡ºæ ¼å¼ï¼š
è«‹æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¼¸å‡ºï¼š
{
  "translated_texts": [
    {
      "original": "åŸæ–‡",
      "translated": "ç¿»è­¯çµæœ"
    }
  ],
  "new_terminology": [
    {
      "japanese": "æ—¥æ–‡åŸæ–‡",
      "chinese": "ä¸­æ–‡ç¿»è­¯"
    }
  ]
}"""

        # æ·»åŠ å°ˆæœ‰åè©å­—å…¸
        if terminology_dict:
            terminology_section = "\n\nç¾æœ‰å°ˆæœ‰åè©å­—å…¸ï¼š\n"
            for jp_term, zh_term in terminology_dict.items():
                terminology_section += f"- {jp_term}: {zh_term}\n"
            base_prompt += terminology_section
        
        # æ·»åŠ ç¿»è­¯æ­·å²ä¸Šä¸‹æ–‡
        if translation_history:
            history_section = "\n\nç¿»è­¯æ­·å²ä¸Šä¸‹æ–‡ï¼ˆç”¨æ–¼ä¿æŒè§’è‰²å’ŒåŠ‡æƒ…çš„ä¸€è‡´æ€§ï¼‰ï¼š\n"
            
            # åªé¡¯ç¤ºæœ€è¿‘çš„20æ¢æ­·å²è¨˜éŒ„ï¼Œé¿å…æç¤ºè©éé•·
            recent_history = translation_history[-20:] if len(translation_history) > 20 else translation_history
            
            for i, hist_item in enumerate(recent_history, 1):
                if isinstance(hist_item, dict) and 'original' in hist_item and 'translated' in hist_item:
                    history_section += f"{i}. {hist_item['original']} â†’ {hist_item['translated']}\n"
            
            history_section += "\nè«‹åƒè€ƒä»¥ä¸Šç¿»è­¯æ­·å²ï¼Œä¿æŒè§’è‰²åç¨±ã€èªªè©±é¢¨æ ¼å’ŒåŠ‡æƒ…çš„ä¸€è‡´æ€§ã€‚"
            base_prompt += history_section
        
        # æ·»åŠ å¾…ç¿»è­¯æ–‡å­—
        if image_path:
            texts_section = "\n\nå¾…æ ¡æ­£å’Œç¿»è­¯çš„ OCR è­˜åˆ¥æ–‡å­—ï¼š\n"
        else:
            texts_section = "\n\nå¾…ç¿»è­¯æ–‡å­—ï¼š\n"
            
        for i, text in enumerate(texts, 1):
            texts_section += f"{i}. {text}\n"
        
        base_prompt += texts_section
        
        base_prompt += "\n\nè«‹é–‹å§‹æ ¡æ­£å’Œç¿»è­¯ï¼š"
        
        return base_prompt
    
    def _parse_translation_response_with_terminology(self, response: str, original_texts: List[str]) -> Dict[str, Any]:
        """
        è§£æåŒ…å«å°ˆæœ‰åè©çš„ç¿»è­¯å›æ‡‰
        
        Args:
            response: APIå›æ‡‰
            original_texts: åŸå§‹æ–‡å­—åˆ—è¡¨
            
        Returns:
            Dict: è§£æå¾Œçš„çµæœ
        """
        try:
            import json
            import re
            
            # å˜—è©¦æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                try:
                    result = json.loads(json_str)
                    
                    # é©—è­‰çµæœæ ¼å¼
                    if 'translated_texts' in result:
                        translated_texts = result['translated_texts']
                        new_terminology = result.get('new_terminology', [])
                        
                        # ç¢ºä¿ç¿»è­¯æ•¸é‡åŒ¹é…
                        if len(translated_texts) == len(original_texts):
                            return {
                                'translated_texts': translated_texts,
                                'new_terminology': new_terminology
                            }
                        else:
                            print(f"âš ï¸ ç¿»è­¯æ•¸é‡ä¸åŒ¹é…: æœŸæœ› {len(original_texts)}, å¾—åˆ° {len(translated_texts)}")
                    
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONè§£æå¤±æ•—: {e}")
                    
            # å¦‚æœJSONè§£æå¤±æ•—ï¼Œå˜—è©¦ç°¡å–®æ–‡å­—è§£æ
            print("âš ï¸ ä½¿ç”¨å‚™ç”¨è§£ææ–¹æ³•")
            return self._fallback_parse_response(response, original_texts)
            
        except Exception as e:
            print(f"âš ï¸ è§£æå›æ‡‰å¤±æ•—: {e}")
            return self._fallback_parse_response(response, original_texts)
    
    def _fallback_parse_response(self, response: str, original_texts: List[str]) -> Dict[str, Any]:
        """
        å‚™ç”¨è§£ææ–¹æ³•
        
        Args:
            response: APIå›æ‡‰
            original_texts: åŸå§‹æ–‡å­—åˆ—è¡¨
            
        Returns:
            Dict: è§£æå¾Œçš„çµæœ
        """
        lines = response.strip().split('\n')
        translated_texts = []
        
        # ç°¡å–®çš„è¡Œå°è¡ŒåŒ¹é…
        translation_lines = [line.strip() for line in lines if line.strip() and not line.startswith('#') and not line.startswith('```')]
        
        for i, original in enumerate(original_texts):
            if i < len(translation_lines):
                translated = translation_lines[i]
                # æ¸…ç†ç¿»è­¯æ–‡å­—
                translated = re.sub(r'^\d+[\.\)]\s*', '', translated)  # ç§»é™¤é–‹é ­çš„æ•¸å­—
                translated = translated.strip()
            else:
                translated = original  # å¦‚æœæ²’æœ‰å°æ‡‰ç¿»è­¯ï¼Œä½¿ç”¨åŸæ–‡
            
            translated_texts.append({
                'original': original,
                'translated': translated
            })
        
        return {
            'translated_texts': translated_texts,
            'new_terminology': []
        }
    
    def get_translation_stats(self) -> Dict[str, Any]:
        """
        ç²å–ç¿»è­¯çµ±è¨ˆè³‡è¨Š
        
        Returns:
            Dict: çµ±è¨ˆè³‡è¨Š
        """
        return {
            'total_api_calls': self.api_call_count,
            'model_used': self.gemini_client.model,
            'cache_size': len(self.translation_cache)
        }
    
    def translate_single(self, text: str, terminology_dict: Dict[str, str] = None) -> Dict[str, Any]:
        """
        ç¿»è­¯å–®å€‹æ–‡å­—
        
        Args:
            text: è¦ç¿»è­¯çš„æ–‡å­—
            terminology_dict: å°ˆæœ‰åè©å­—å…¸
            
        Returns:
            Dict: ç¿»è­¯çµæœ
        """
        result = self.translate_texts([text], terminology_dict)
        
        if result['success'] and result['translated_texts']:
            return {
                'original': result['translated_texts'][0]['original'],
                'translated': result['translated_texts'][0]['translated'],
                'success': True
            }
        else:
            return {
                'original': text,
                'translated': text,
                'success': False
            }
    
    def _create_fallback_translations(self, texts: List[str]) -> List[Dict[str, str]]:
        """
        å‰µå»ºå‚™ç”¨ç¿»è­¯çµæœï¼ˆç•¶ç¿»è­¯å¤±æ•—æ™‚ä½¿ç”¨ï¼‰
        
        Args:
            texts: åŸå§‹æ–‡å­—åˆ—è¡¨
            
        Returns:
            List[Dict]: å‚™ç”¨ç¿»è­¯çµæœ
        """
        return [
            {
                'original': text,
                'translated': text,
                'text_direction': 'horizontal',
                'bubble_type': 'pure_white',
                'estimated_font_size': 16
            }
            for text in texts
        ] 