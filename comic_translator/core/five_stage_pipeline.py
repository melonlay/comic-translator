"""
Five Stage Manga Translation Pipeline
5éšæ®µæ¼«ç•«ç¿»è­¯æµç¨‹ç®¡ç†å™¨

æ•´åˆæ‰€æœ‰æ¨¡çµ„ï¼Œå¯¦ç¾å®Œæ•´çš„5éšæ®µç¿»è­¯æµç¨‹
"""

import time
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List

from ..detection.comic_text_detector import ComicTextDetector
from ..extraction.manga_ocr_extractor import MangaOCRExtractor
from ..translation.text_reorder import TextReorder
from ..translation.text_translator import TextTranslator
from ..terminology.terminology_manager import TerminologyManager
from ..utils.gemini_client import GeminiClient
from ..utils.stage_manager import StageManager


class FiveStagePipeline:
    """5éšæ®µæ¼«ç•«ç¿»è­¯æµç¨‹ç®¡ç†å™¨"""
    
    def __init__(self, gemini_api_key: str = None):
        """
        åˆå§‹åŒ–5éšæ®µæµç¨‹
        
        Args:
            gemini_api_key: Gemini APIå¯†é‘°
        """
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–5éšæ®µæ¼«ç•«ç¿»è­¯æµç¨‹...")
        
        self.initialized = False
        self.translation_history = []  # ç¿»è­¯æ­·å²è¨˜éŒ„
        
        try:
            # åˆå§‹åŒ–å„å€‹çµ„ä»¶
            self.detector = ComicTextDetector()
            self.ocr_extractor = MangaOCRExtractor()
            self.terminology_manager = TerminologyManager()
            self.stage_manager = StageManager()
            
            # åˆå§‹åŒ–Geminiç›¸é—œçµ„ä»¶
            self.gemini_client = GeminiClient(gemini_api_key)
            self.text_reorder = TextReorder(self.gemini_client)
            self.text_translator = TextTranslator(self.gemini_client)
            
            self.initialized = True
            print("âœ… 5éšæ®µæµç¨‹åˆå§‹åŒ–å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ 5éšæ®µæµç¨‹åˆå§‹åŒ–å¤±æ•—: {e}")
            self.initialized = False
    
    def batch_process_folder(self, input_folder: str, output_folder: str = None) -> Dict[str, Any]:
        """
        æ‰¹é‡è™•ç†è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡
        
        Args:
            input_folder: è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘
            output_folder: è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘ï¼ˆå¯é¸ï¼‰
            
        Returns:
            Dict: æ‰¹é‡è™•ç†çµæœ
        """
        if not self.initialized:
            print("âŒ ç³»çµ±æœªåˆå§‹åŒ–")
            return {"success": False, "error": "System not initialized"}
        
        input_path = Path(input_folder)
        if not input_path.exists() or not input_path.is_dir():
            print(f"âŒ è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {input_folder}")
            return {"success": False, "error": f"Input folder not found: {input_folder}"}
        
        # è¨­å®šè¼¸å‡ºè³‡æ–™å¤¾
        if output_folder is None:
            output_path = input_path.parent / f"{input_path.name}_translated"
        else:
            output_path = Path(output_folder)
        
        output_path.mkdir(exist_ok=True)
        
        # ç²å–æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆä¸¦æ’åº
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = []
        
        for file_path in input_path.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in image_extensions:
                image_files.append(file_path)
        
        # æŒ‰æª”æ¡ˆåç¨±æ’åºï¼ˆç”±å°åˆ°å¤§ï¼‰
        image_files.sort(key=lambda x: x.name.lower())
        
        if not image_files:
            print(f"âš ï¸ åœ¨è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡æª”æ¡ˆ: {input_folder}")
            return {"success": False, "error": "No image files found"}
        
        print(f"\nğŸ“ é–‹å§‹æ‰¹é‡è™•ç†è³‡æ–™å¤¾: {input_folder}")
        print(f"ğŸ“¸ æ‰¾åˆ° {len(image_files)} å€‹åœ–ç‰‡æª”æ¡ˆ")
        print(f"ğŸ“¤ è¼¸å‡ºè³‡æ–™å¤¾: {output_path}")
        print("=" * 80)
        
        # é‡ç½®ç¿»è­¯æ­·å²
        self.translation_history = []
        
        batch_results = {
            "success": True,
            "input_folder": str(input_path),
            "output_folder": str(output_path),
            "total_images": len(image_files),
            "processed_images": [],
            "failed_images": [],
            "start_time": time.time(),
            "translation_history": []
        }
        
        # é€ä¸€è™•ç†æ¯å¼µåœ–ç‰‡
        for i, image_file in enumerate(image_files, 1):
            print(f"\nğŸ–¼ï¸  è™•ç†ç¬¬ {i}/{len(image_files)} å¼µåœ–ç‰‡: {image_file.name}")
            print("-" * 60)
            
            try:
                # è¨­å®šè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
                output_file = output_path / f"translated_{image_file.name}"
                
                # è™•ç†å–®å¼µåœ–ç‰‡
                result = self.process_manga_with_history(str(image_file), str(output_file))
                
                if result and result.get("success"):
                    batch_results["processed_images"].append({
                        "input_file": str(image_file),
                        "output_file": str(output_file),
                        "result": result
                    })
                    
                    # æ›´æ–°ç¿»è­¯æ­·å²
                    if result.get("translated_texts"):
                        self.translation_history.extend(result["translated_texts"])
                        # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœå…§ï¼ˆæœ€å¤šä¿ç•™100å€‹ç¿»è­¯ï¼‰
                        if len(self.translation_history) > 100:
                            self.translation_history = self.translation_history[-100:]
                    
                    print(f"âœ… ç¬¬ {i} å¼µåœ–ç‰‡è™•ç†æˆåŠŸ")
                else:
                    batch_results["failed_images"].append({
                        "input_file": str(image_file),
                        "error": result.get("error", "Unknown error") if result else "No result"
                    })
                    print(f"âŒ ç¬¬ {i} å¼µåœ–ç‰‡è™•ç†å¤±æ•—")
                
            except Exception as e:
                batch_results["failed_images"].append({
                    "input_file": str(image_file),
                    "error": str(e)
                })
                print(f"âŒ ç¬¬ {i} å¼µåœ–ç‰‡è™•ç†ç•°å¸¸: {e}")
            
            # é¡¯ç¤ºç•¶å‰ç¿»è­¯æ­·å²ç‹€æ…‹
            print(f"ğŸ“š ç•¶å‰ç¿»è­¯æ­·å²: {len(self.translation_history)} æ¢è¨˜éŒ„")
            print(f"ğŸ“– å°ˆæœ‰åè©å­—å…¸: {len(self.terminology_manager.get_all_terms())} å€‹è©å½™")
        
        # å®Œæˆè™•ç†
        batch_results["end_time"] = time.time()
        batch_results["total_time"] = batch_results["end_time"] - batch_results["start_time"]
        batch_results["success_rate"] = len(batch_results["processed_images"]) / len(image_files)
        batch_results["translation_history"] = self.translation_history.copy()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰¹é‡è™•ç†å®Œæˆ!")
        print(f"ğŸ“Š è™•ç†çµ±è¨ˆ:")
        print(f"   ç¸½åœ–ç‰‡æ•¸: {batch_results['total_images']}")
        print(f"   æˆåŠŸè™•ç†: {len(batch_results['processed_images'])}")
        print(f"   è™•ç†å¤±æ•—: {len(batch_results['failed_images'])}")
        print(f"   æˆåŠŸç‡: {batch_results['success_rate']:.1%}")
        print(f"   ç¸½è€—æ™‚: {batch_results['total_time']:.1f} ç§’")
        print(f"   ç´¯ç©ç¿»è­¯æ­·å²: {len(batch_results['translation_history'])} æ¢")
        
        return batch_results
    
    def process_manga_with_history(self, image_path: str, output_path: str = None) -> Optional[Dict[str, Any]]:
        """
        è™•ç†å–®å¼µæ¼«ç•«ï¼Œä¸¦ä½¿ç”¨ç¿»è­¯æ­·å²ä½œç‚ºä¸Šä¸‹æ–‡
        
        Args:
            image_path: æ¼«ç•«åœ–åƒè·¯å¾‘
            output_path: è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            
        Returns:
            Optional[Dict]: è™•ç†çµæœï¼Œå¤±æ•—æ™‚è¿”å›None
        """
        if not self.initialized:
            print("âŒ ç³»çµ±æœªåˆå§‹åŒ–")
            return None
        
        print(f"\nğŸŒ é–‹å§‹è™•ç†æ¼«ç•«: {Path(image_path).name}")
        
        image_name = Path(image_path).stem
        start_time = time.time()
        
        try:
            # åŸ·è¡Œå‰4å€‹éšæ®µ
            text_boxes = self.stage1_detect_text_boxes(image_path, image_name)
            if not text_boxes:
                print("âš ï¸ æœªæª¢æ¸¬åˆ°æ–‡å­—æ¡†")
                return {"success": False, "error": "No text boxes detected"}
            
            extracted_texts = self.stage2_ocr_extraction(image_path, text_boxes, image_name)
            if not extracted_texts:
                print("âš ï¸ æœªæ“·å–åˆ°æ–‡å­—")
                return {"success": False, "error": "No text extracted"}
            
            reordered_texts = self.stage3_reorder_text(extracted_texts, image_path, image_name)
            if not reordered_texts:
                print("âš ï¸ æ–‡å­—é‡æ’åºå¤±æ•—")
                return {"success": False, "error": "Text reordering failed"}
            
            # éšæ®µ4ï¼šä½¿ç”¨æ­·å²ä¸Šä¸‹æ–‡é€²è¡Œç¿»è­¯
            translation_result = self.stage4_translate_with_history(reordered_texts, image_name, image_path)
            if not translation_result.get("success"):
                print("âš ï¸ ç¿»è­¯å¤±æ•—")
                return {"success": False, "error": "Translation failed"}
            
            # éšæ®µ5ï¼šæ›´æ–°å°ˆæœ‰åè©å­—å…¸
            self.stage5_update_terminology(translation_result.get("new_terminology", {}))
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            processing_time = time.time() - start_time
            
            # ä¿å­˜è¼¸å‡ºï¼ˆå¦‚æœæŒ‡å®šäº†è¼¸å‡ºè·¯å¾‘ï¼‰
            if output_path:
                self.save_translation_result(image_path, translation_result["translated_texts"], output_path)
            
            print(f"âœ… æ¼«ç•«è™•ç†å®Œæˆï¼Œè€—æ™‚: {processing_time:.2f}ç§’")
            
            return {
                "success": True,
                "input_path": image_path,
                "output_path": output_path,
                "processing_time": processing_time,
                "text_boxes_count": len(text_boxes),
                "extracted_count": len(extracted_texts),
                "reordered_count": len(reordered_texts),
                "translated_count": len(translation_result["translated_texts"]),
                "new_terminology_count": len(translation_result.get("new_terminology", {})),
                "translated_texts": translation_result["translated_texts"],
                "stages": {
                    "stage1": len(text_boxes),
                    "stage2": len(extracted_texts),
                    "stage3": len(reordered_texts),
                    "stage4": len(translation_result["translated_texts"]),
                    "stage5": "completed"
                }
            }
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•—: {e}")
            return {"success": False, "error": str(e)}
    
    def stage4_translate_with_history(self, reordered_texts: list, image_name: str, image_path: str = None) -> dict:
        """éšæ®µ4ï¼šä½¿ç”¨æ­·å²ä¸Šä¸‹æ–‡ç¿»è­¯æ–‡å­—"""
        print("\nğŸŒ éšæ®µ4ï¼šç¿»è­¯æ–‡å­—ï¼ˆä½¿ç”¨æ­·å²ä¸Šä¸‹æ–‡å’Œåœ–ç‰‡åˆ†æï¼‰")
        
        # æª¢æŸ¥å¿«å–
        cached = self.stage_manager.load_stage_result(4, image_name)
        if cached:
            print(f"ğŸ“ è¼‰å…¥å¿«å–çµæœ: {len(cached['translated_texts'])} å€‹ç¿»è­¯æ–‡å­—")
            return cached
        
        if not reordered_texts:
            return {'translated_texts': [], 'new_terminology': {}, 'success': False}
        
        # è®€å–stage2çš„OCRçµæœä»¥ç²å–verticalè³‡è¨Š
        stage2_result = self.stage_manager.load_stage_result(2, image_name)
        ocr_metadata = {}
        if stage2_result and stage2_result.get('extracted_texts'):
            # å»ºç«‹box_indexåˆ°OCRçµæœçš„æ˜ å°„
            for item in stage2_result['extracted_texts']:
                box_index = item.get('box_index')
                if box_index is not None:
                    ocr_metadata[box_index] = item
        
        # æå–æ–‡å­—å­—ä¸²åˆ—è¡¨ï¼ˆå¦‚æœreordered_textsæ˜¯å­—å…¸åˆ—è¡¨çš„è©±ï¼‰
        if reordered_texts and isinstance(reordered_texts[0], dict):
            # reordered_textsæ˜¯å­—å…¸åˆ—è¡¨ï¼Œéœ€è¦æå–textæ¬„ä½
            text_strings = [item.get('text', '') for item in reordered_texts if item.get('text')]
        else:
            # reordered_textså·²ç¶“æ˜¯å­—ä¸²åˆ—è¡¨
            text_strings = [str(text) for text in reordered_texts if text]
        
        if not text_strings:
            return {'translated_texts': [], 'new_terminology': {}, 'success': False}
        
        # ç²å–ç¾æœ‰å°ˆæœ‰åè©å­—å…¸
        terminology_dict = self.terminology_manager.get_all_terms()
        
        # åŸ·è¡Œç¿»è­¯ï¼ˆå‚³å…¥æ­·å²ä¸Šä¸‹æ–‡å’Œåœ–ç‰‡è·¯å¾‘ï¼‰
        result = self.text_translator.translate_texts_with_history(
            text_strings, 
            terminology_dict, 
            self.translation_history,
            image_path  # å‚³éåœ–ç‰‡è·¯å¾‘
        )
        
        # å¦‚æœåŸå§‹è¼¸å…¥æ˜¯å­—å…¸åˆ—è¡¨ï¼Œéœ€è¦åˆä½µä½ç½®è³‡è¨Š
        if reordered_texts and isinstance(reordered_texts[0], dict):
            final_translations = []
            for i, original_item in enumerate(reordered_texts):
                if i < len(result['translated_texts']):
                    translation_item = result['translated_texts'][i]
                    
                    # å¾OCRçµæœä¸­ç²å–verticalè³‡è¨Š
                    original_index = original_item.get('original_index')
                    ocr_info = ocr_metadata.get(original_index, {})
                    is_vertical = ocr_info.get('vertical', False)
                    
                    final_translations.append({
                        'original_index': original_item.get('original_index'),
                        'new_order': original_item.get('new_order'),
                        'bbox': original_item.get('bbox'),
                        'original': translation_item['original'],
                        'translated': translation_item['translated'],
                        'text_direction': 'vertical' if is_vertical else 'horizontal',  # ç›´æ¥å¾OCRçš„verticalæ¬„ä½æ±ºå®š
                        'bubble_type': translation_item.get('bubble_type', 'pure_white'),
                        'estimated_font_size': translation_item.get('estimated_font_size', 16)
                    })
            result['translated_texts'] = final_translations
        
        # ä¿å­˜çµæœ
        save_result = {
            'total_texts': len(reordered_texts),
            'translated_count': len(result['translated_texts']),
            'translated_texts': result['translated_texts'],
            'new_terminology': result['new_terminology'],
            'success': result['success'],
            'history_context_used': len(self.translation_history),
            'used_image_analysis': image_path is not None,
            'used_ocr_vertical_info': len(ocr_metadata) > 0
        }
        
        self.stage_manager.save_stage_result(4, image_name, save_result)
        analysis_method = "åœ–ç‰‡è¦–è¦ºåˆ†æ" if image_path else "ç´”æ–‡å­—åˆ†æ"
        ocr_info_used = f"ï¼Œä½¿ç”¨OCRå‚ç›´ä¿¡æ¯({len(ocr_metadata)}å€‹)" if ocr_metadata else ""
        print(f"âœ… ç¿»è­¯å®Œæˆ: {len(result['translated_texts'])} å€‹æ–‡å­—ï¼Œä½¿ç”¨ {analysis_method}{ocr_info_used}")
        print(f"ğŸ“š ä½¿ç”¨ {len(self.translation_history)} æ¢æ­·å²ä¸Šä¸‹æ–‡")
        print(f"ğŸ†• ç™¼ç¾ {len(result['new_terminology'])} å€‹æ–°å°ˆæœ‰åè©")
        
        return result
    
    def stage1_detect_text_boxes(self, image_path: str, image_name: str) -> list:
        """éšæ®µ1ï¼šåµæ¸¬æ–‡å­—å°è©±æ¡†"""
        print("\nğŸ” éšæ®µ1ï¼šåµæ¸¬æ–‡å­—å°è©±æ¡†")
        
        # æª¢æŸ¥å¿«å–
        cached = self.stage_manager.load_stage_result(1, image_name)
        if cached:
            print(f"ğŸ“ è¼‰å…¥å¿«å–çµæœ: {len(cached['text_boxes'])} å€‹æ–‡å­—æ¡†")
            return cached['text_boxes']
        
        # åŸ·è¡Œæª¢æ¸¬
        result = self.detector.detect_with_metadata(image_path)
        text_boxes = result['text_boxes']
        
        # ä¿å­˜çµæœ
        self.stage_manager.save_stage_result(1, image_name, result)
        print(f"âœ… æª¢æ¸¬åˆ° {len(text_boxes)} å€‹æ–‡å­—æ¡†")
        
        return text_boxes
    
    def stage2_ocr_extraction(self, image_path: str, text_boxes: list, image_name: str) -> list:
        """éšæ®µ2ï¼šOCRæ“·å–æ–‡å­—"""
        print("\nğŸ“ éšæ®µ2ï¼šOCRæ“·å–æ–‡å­—")
        
        # æª¢æŸ¥å¿«å–
        cached = self.stage_manager.load_stage_result(2, image_name)
        if cached:
            print(f"ğŸ“ è¼‰å…¥å¿«å–çµæœ: {len(cached['extracted_texts'])} å€‹æ“·å–æ–‡å­—")
            return cached['extracted_texts']
        
        # åŸ·è¡ŒOCR
        extracted_texts = self.ocr_extractor.extract_from_boxes(image_path, text_boxes)
        
        # ä¿å­˜çµæœ
        result = {
            'total_boxes': len(text_boxes),
            'successful_extractions': len(extracted_texts),
            'extraction_rate': len(extracted_texts) / len(text_boxes) if text_boxes else 0,
            'extracted_texts': extracted_texts
        }
        
        self.stage_manager.save_stage_result(2, image_name, result)
        print(f"âœ… æˆåŠŸæ“·å– {len(extracted_texts)}/{len(text_boxes)} å€‹æ–‡å­—æ¡†")
        
        return extracted_texts
    
    def stage3_reorder_text(self, extracted_texts: list, image_path: str, image_name: str) -> list:
        """éšæ®µ3ï¼šé‡æ–°æ’åºæ–‡å­—ï¼ˆä½¿ç”¨åœ–ç‰‡ï¼‰"""
        print("\nğŸ”„ éšæ®µ3ï¼šé‡æ–°æ’åºæ–‡å­—")
        
        # æª¢æŸ¥å¿«å–
        cached = self.stage_manager.load_stage_result(3, image_name)
        if cached:
            print(f"ğŸ“ è¼‰å…¥å¿«å–çµæœ: {len(cached['reordered_texts'])} å€‹é‡æ’åºæ–‡å­—")
            return cached['reordered_texts']
        
        if not extracted_texts:
            return []
        
        # åŸ·è¡Œé‡æ’åºï¼ˆä½¿ç”¨æ–°çš„åœ–ç‰‡é‡æ’åºåŠŸèƒ½ï¼‰
        try:
            reordered_texts = self.text_reorder.reorder_texts_with_image(image_path, extracted_texts)
            
            result = {
                'total_texts': len(extracted_texts),
                'reordered_count': len(reordered_texts),
                'reordered_texts': reordered_texts,
                'success': len(reordered_texts) > 0,
                'method': 'image_based_structured_output'
            }
            
        except Exception as e:
            print(f"âš ï¸ åœ–ç‰‡é‡æ’åºå¤±æ•—ï¼Œå›é€€åˆ°èˆŠæ–¹æ³•: {e}")
            
            # å›é€€åˆ°èˆŠçš„é‡æ’åºæ–¹æ³•
            result = self.text_reorder.reorder_with_metadata(extracted_texts)
            result['method'] = 'fallback_text_only'
            reordered_texts = result['reordered_texts']
        
        # ä¿å­˜çµæœ
        self.stage_manager.save_stage_result(3, image_name, result)
        print(f"âœ… é‡æ’åºå®Œæˆ: {len(reordered_texts)} å€‹æ–‡å­—")
        
        return reordered_texts
    
    def stage5_update_terminology(self, new_terminology: dict):
        """éšæ®µ5ï¼šæ›´æ–°å°ˆæœ‰åè©å­—å…¸"""
        print("\nğŸ“š éšæ®µ5ï¼šæ›´æ–°å°ˆæœ‰åè©å­—å…¸")
        
        if not new_terminology:
            print("âš ï¸ æ²’æœ‰æ–°çš„å°ˆæœ‰åè©éœ€è¦æ›´æ–°")
            return
        
        # æ›´æ–°å°ˆæœ‰åè©å­—å…¸
        added_count = self.terminology_manager.update_terms(new_terminology)
        print(f"âœ… å­—å…¸æ›´æ–°å®Œæˆï¼Œæ–°å¢ {added_count} å€‹è©å½™")
    
    def process_manga(self, image_path: str) -> Optional[Dict[str, Any]]:
        """
        è™•ç†æ•´å€‹5éšæ®µæµç¨‹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼Œä¸ä½¿ç”¨æ­·å²ä¸Šä¸‹æ–‡ï¼‰
        
        Args:
            image_path: æ¼«ç•«åœ–åƒè·¯å¾‘
            
        Returns:
            Optional[Dict]: è™•ç†çµæœï¼Œå¤±æ•—æ™‚è¿”å›None
        """
        return self.process_manga_with_history(image_path, None)
    
    def get_progress(self, image_name: str) -> Dict[str, Any]:
        """
        ç²å–è™•ç†é€²åº¦
        
        Args:
            image_name: åœ–åƒåç¨±
            
        Returns:
            Dict: é€²åº¦è³‡è¨Š
        """
        progress = self.stage_manager.get_progress(image_name)
        
        completed_stages = sum(1 for completed in progress.values() if completed)
        
        return {
            'completed_stages': completed_stages,
            'total_stages': 5,
            'progress_percentage': (completed_stages / 5) * 100,
            'stage_details': progress
        }
    
    def clear_cache(self, image_name: str = None) -> int:
        """
        æ¸…é™¤å¿«å–
        
        Args:
            image_name: åœ–åƒåç¨±ï¼Œå¦‚æœæœªæŒ‡å®šå‰‡æ¸…é™¤æ‰€æœ‰å¿«å–
            
        Returns:
            int: æ¸…é™¤çš„æª”æ¡ˆæ•¸é‡
        """
        if image_name:
            return self.stage_manager.clear_all_stages(image_name)
        else:
            # æ¸…é™¤æ‰€æœ‰å¿«å–éœ€è¦åˆ—å‡ºæ‰€æœ‰æª”æ¡ˆ
            results = self.stage_manager.list_results()
            cleared_count = 0
            
            for file_info in results['files']:
                file_name = file_info['name']
                if '_stage' in file_name:
                    # æå–åœ–åƒåç¨±
                    parts = file_name.split('_stage')
                    if parts:
                        img_name = parts[0]
                        cleared_count += self.stage_manager.clear_all_stages(img_name)
            
            return cleared_count
    
    def get_system_info(self) -> Dict[str, Any]:
        """
        ç²å–ç³»çµ±è³‡è¨Š
        
        Returns:
            Dict: ç³»çµ±è³‡è¨Š
        """
        return {
            'initialized': self.initialized,
            'detector_config': self.detector.config if hasattr(self.detector, 'config') else {},
            'ocr_device_info': self.ocr_extractor.get_device_info(),
            'gemini_model_info': self.gemini_client.get_model_info(),
            'terminology_stats': self.terminology_manager.get_statistics(),
            'results_directory': str(self.stage_manager.results_dir.absolute())
        }
    
    def save_translation_result(self, input_path: str, translated_texts: list, output_path: str):
        """ä¿å­˜ç¿»è­¯çµæœåˆ°æª”æ¡ˆ"""
        try:
            # é€™è£¡å¯ä»¥å¯¦ç¾ä¿å­˜ç¿»è­¯çµæœçš„é‚è¼¯
            # ç›®å‰å…ˆç°¡å–®è¤‡è£½åŸåœ–
            import shutil
            shutil.copy2(input_path, output_path)
            
            # åŒæ™‚ä¿å­˜ç¿»è­¯æ–‡å­—åˆ°JSONæª”æ¡ˆ
            import json
            json_path = Path(output_path).with_suffix('.json')
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'input_file': input_path,
                    'translated_texts': translated_texts,
                    'timestamp': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ç¿»è­¯çµæœå·²ä¿å­˜: {output_path}")
            print(f"ğŸ“„ ç¿»è­¯æ–‡å­—å·²ä¿å­˜: {json_path}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç¿»è­¯çµæœå¤±æ•—: {e}") 