#!/usr/bin/env python3
"""
æ¼«ç•«ç¿»è­¯å™¨ - ç¿»è­¯åŸ·è¡Œæª”æ¡ˆ
Comic Translator - Translation Runner

æ•´åˆäº”éšæ®µç¿»è­¯æµç¨‹ï¼š
1. æ–‡å­—æª¢æ¸¬ (Text Detection)
2. æ–‡å­—è­˜åˆ¥ (OCR)  
3. æ–‡å­—é‡æ’ (Text Reordering)
4. æ–‡å­—ç¿»è­¯ (Translation)
5. çµæœè¼¸å‡º (Output)

ç”¨æ³•:
    python run/translate.py <image_path>               # å–®å¼µåœ–ç‰‡
    python run/translate.py test_images/ --batch      # æ‰¹é‡è™•ç†
"""

import sys
import os
from pathlib import Path
import argparse
import datetime

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

from comic_translator.detection import ComicTextDetector
from comic_translator.extraction import MangaOCRExtractor  
from comic_translator.translation import TextReorder, TextTranslator
from comic_translator.utils import GeminiClient
import json


class ComicTranslator:
    """æ¼«ç•«ç¿»è­¯å™¨ä¸»é¡"""
    
    def __init__(self, output_dir: str = "output"):
        """
        åˆå§‹åŒ–ç¿»è­¯å™¨
        
        Args:
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.output_dir = Path(output_dir)
        
        # å‰µå»ºå„éšæ®µçš„è¼¸å‡ºç›®éŒ„
        self.stage1_dir = self.output_dir / "stage1_detection"
        self.stage2_dir = self.output_dir / "stage2_ocr"
        self.stage3_dir = self.output_dir / "stage3_reorder"
        self.stage4_dir = self.output_dir / "stage4_translate"
        
        # ç¢ºä¿æ‰€æœ‰è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.output_dir.mkdir(exist_ok=True)
        self.stage1_dir.mkdir(exist_ok=True)
        self.stage2_dir.mkdir(exist_ok=True)
        self.stage3_dir.mkdir(exist_ok=True)
        self.stage4_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–å„éšæ®µçµ„ä»¶
        print("ğŸ”§ åˆå§‹åŒ–çµ„ä»¶...")
        self.detector = ComicTextDetector()
        self.ocr = MangaOCRExtractor()
        
        # åˆå§‹åŒ–Geminiå®¢æˆ¶ç«¯å’Œç¿»è­¯å™¨
        self.gemini_client = GeminiClient()
        self.reorder = TextReorder(self.gemini_client)
        self.translator = TextTranslator(self.gemini_client)
        
        # è¼‰å…¥terminologyå­—å…¸
        self.terminology_dict = self._load_terminology_dict()
        
        print(f"âœ… æ¼«ç•«ç¿»è­¯å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        print(f"ğŸ” Stage1 ç›®éŒ„: {self.stage1_dir}")
        print(f"ğŸ“ Stage2 ç›®éŒ„: {self.stage2_dir}")
        print(f"ğŸ”„ Stage3 ç›®éŒ„: {self.stage3_dir}")
        print(f"ğŸŒ Stage4 ç›®éŒ„: {self.stage4_dir}")
        print(f"ğŸ“š å°ˆæœ‰åè©: {len(self.terminology_dict)} å€‹è©å½™")
    
    def _load_terminology_dict(self) -> dict:
        """è¼‰å…¥å°ˆæœ‰åè©å­—å…¸"""
        terminology_file = Path("terminology_dict.json")
        
        if terminology_file.exists():
            try:
                with open(terminology_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    terminology = data.get('ja_to_zh', {})
                    print(f"ğŸ“š è¼‰å…¥å°ˆæœ‰åè©å­—å…¸: {len(terminology)} å€‹è©å½™")
                    return terminology
            except Exception as e:
                print(f"âš ï¸ è¼‰å…¥å°ˆæœ‰åè©å­—å…¸å¤±æ•—: {e}")
                return {}
        else:
            print("âš ï¸ å°ˆæœ‰åè©å­—å…¸ä¸å­˜åœ¨: terminology_dict.json")
            return {}
    
    def _save_terminology_dict(self, new_terminology: dict):
        """ä¿å­˜æ–°çš„å°ˆæœ‰åè©åˆ°å­—å…¸"""
        if not new_terminology:
            return
        
        terminology_file = Path("terminology_dict.json")
        
        try:
            # è®€å–ç¾æœ‰å­—å…¸
            current_data = {}
            if terminology_file.exists():
                with open(terminology_file, 'r', encoding='utf-8') as f:
                    current_data = json.load(f)
            
            # ç²å–ç¾æœ‰çš„å°ˆæœ‰åè©å­—å…¸
            terminology = current_data.get('ja_to_zh', {})
            
            added_count = 0
            updated_count = 0
            
            # è™•ç†æ–°çš„å°ˆæœ‰åè©
            for jp_term, cn_term in new_terminology.items():
                if not jp_term or not cn_term:
                    continue
                
                if jp_term in terminology:
                    if terminology[jp_term] != cn_term:
                        print(f"ğŸ”„ æ›´æ–°å°ˆæœ‰åè©: {jp_term}")
                        print(f"   èˆŠ: {terminology[jp_term]}")
                        print(f"   æ–°: {cn_term}")
                        terminology[jp_term] = cn_term
                        updated_count += 1
                else:
                    print(f"ğŸ“ æ–°å¢å°ˆæœ‰åè©: {jp_term} â†’ {cn_term}")
                    terminology[jp_term] = cn_term
                    added_count += 1
            
            if added_count > 0 or updated_count > 0:
                # æ›´æ–°æ•¸æ“šçµæ§‹
                current_data['ja_to_zh'] = terminology
                current_data.setdefault('metadata', {})
                current_data['metadata']['updated_at'] = datetime.datetime.now().isoformat()
                current_data['metadata']['total_terms'] = len(terminology)
                current_data['metadata']['version'] = '1.0'
                
                # ä¿å­˜æ–‡ä»¶
                with open(terminology_file, 'w', encoding='utf-8') as f:
                    json.dump(current_data, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… å°ˆæœ‰åè©å­—å…¸å·²æ›´æ–°: +{added_count} æ–°å¢, {updated_count} æ›´æ–°")
                
                # æ›´æ–°å…§å­˜ä¸­çš„å­—å…¸
                self.terminology_dict = terminology
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å°ˆæœ‰åè©å­—å…¸å¤±æ•—: {e}")
    
    def translate_image(self, image_path: str) -> bool:
        """
        ç¿»è­¯å–®å¼µåœ–ç‰‡
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            
        Returns:
            bool: ç¿»è­¯æ˜¯å¦æˆåŠŸ
        """
        image_path = Path(image_path)
        
        if not image_path.exists():
            print(f"âŒ åœ–ç‰‡ä¸å­˜åœ¨: {image_path}")
            return False
        
        print(f"\nğŸ¨ é–‹å§‹ç¿»è­¯åœ–ç‰‡: {image_path.name}")
        print("=" * 70)
        
        try:
            # éšæ®µ1: æ–‡å­—æª¢æ¸¬
            print("ğŸ” éšæ®µ1: æ–‡å­—æª¢æ¸¬")
            stage1_result = self._stage1_detection(image_path)
            if not stage1_result:
                return False
            
            # éšæ®µ2: æ–‡å­—è­˜åˆ¥  
            print("ğŸ“ éšæ®µ2: æ–‡å­—è­˜åˆ¥")
            stage2_result = self._stage2_ocr(image_path, stage1_result)
            if not stage2_result:
                return False
            
            # éšæ®µ3: æ–‡å­—é‡æ’
            print("ğŸ”„ éšæ®µ3: æ–‡å­—é‡æ’")
            stage3_result = self._stage3_reorder(image_path, stage2_result)
            if not stage3_result:
                return False
            
            # éšæ®µ4: æ–‡å­—ç¿»è­¯
            print("ğŸŒ éšæ®µ4: æ–‡å­—ç¿»è­¯")
            stage4_result = self._stage4_translate(image_path, stage3_result)
            if not stage4_result:
                return False
            
            print(f"âœ… ç¿»è­¯å®Œæˆ: {image_path.name}")
            print(f"ğŸ“„ çµæœä¿å­˜åœ¨: {self.output_dir}")
            return True
            
        except Exception as e:
            print(f"âŒ ç¿»è­¯éç¨‹å‡ºéŒ¯: {e}")
            return False
    
    def batch_translate_folder(self, folder_path: str) -> list:
        """
        æ‰¹é‡ç¿»è­¯è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡
        
        Args:
            folder_path: åŒ…å«åœ–ç‰‡çš„è³‡æ–™å¤¾è·¯å¾‘
            
        Returns:
            list: æˆåŠŸç¿»è­¯çš„åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
        """
        folder = Path(folder_path)
        if not folder.exists() or not folder.is_dir():
            print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
            return []
        
        # ç²å–æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = []
        
        for file_path in folder.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in image_extensions:
                image_files.append(file_path)
        
        image_files.sort(key=lambda x: x.name.lower())
        
        print(f"\nğŸ“ æ‰¹é‡ç¿»è­¯è³‡æ–™å¤¾: {folder_path}")
        print("=" * 70)
        print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(image_files)} å€‹åœ–ç‰‡æª”æ¡ˆ")
        
        translated_files = []
        
        for i, image_file in enumerate(image_files, 1):
            print(f"\nğŸ¨ ç¿»è­¯ç¬¬ {i}/{len(image_files)} å¼µ: {image_file.name}")
            
            success = self.translate_image(str(image_file))
            if success:
                translated_files.append(str(image_file))
                print(f"âœ… ç¿»è­¯æˆåŠŸ")
            else:
                print(f"âš ï¸ ç¿»è­¯å¤±æ•—")
        
        print(f"\nğŸ‰ æ‰¹é‡ç¿»è­¯å®Œæˆ: {len(translated_files)}/{len(image_files)} æˆåŠŸ")
        return translated_files
    
    def _stage1_detection(self, image_path: Path) -> dict:
        """éšæ®µ1: æ–‡å­—æª¢æ¸¬"""
        result = self.detector.detect_with_metadata(str(image_path))
        
        if result and result.get('text_boxes'):
            # ä¿å­˜çµæœ
            output_file = self.stage1_dir / f"{image_path.stem}_stage1_detection.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… æª¢æ¸¬åˆ° {result['total_boxes']} å€‹æ–‡å­—å€åŸŸ")
            print(f"   ğŸ’¾ çµæœä¿å­˜: {output_file.name}")
            return result
        else:
            print("   âŒ æ–‡å­—æª¢æ¸¬å¤±æ•—")
            return None
    
    def _stage2_ocr(self, image_path: Path, stage1_result: dict) -> dict:
        """éšæ®µ2: æ–‡å­—è­˜åˆ¥"""
        result_data = self.ocr.extract_from_boxes(str(image_path), stage1_result['text_boxes'])
        
        result = {
            'extracted_texts': result_data,
            'total_texts': len(result_data),
            'source_image': str(image_path)
        }
        
        if result and result.get('extracted_texts'):
            # ä¿å­˜çµæœ
            output_file = self.stage2_dir / f"{image_path.stem}_stage2_ocr.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… è­˜åˆ¥åˆ° {len(result['extracted_texts'])} æ®µæ–‡å­—")
            print(f"   ğŸ’¾ çµæœä¿å­˜: {output_file.name}")
            return result
        else:
            print("   âŒ æ–‡å­—è­˜åˆ¥å¤±æ•—")
            return None
    
    def _stage3_reorder(self, image_path: Path, stage2_result: dict) -> dict:
        """éšæ®µ3: æ–‡å­—é‡æ’"""
        reordered_texts = self.reorder.reorder_texts_with_image(str(image_path), stage2_result['extracted_texts'])
        
        result = {
            'reordered_texts': reordered_texts,
            'total_texts': len(reordered_texts),
            'source_image': str(image_path)
        }
        
        if result and result.get('reordered_texts'):
            # ä¿å­˜çµæœ
            output_file = self.stage3_dir / f"{image_path.stem}_stage3_reorder.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… é‡æ’å®Œæˆ {len(result['reordered_texts'])} æ®µæ–‡å­—")
            print(f"   ğŸ’¾ çµæœä¿å­˜: {output_file.name}")
            return result
        else:
            print("   âŒ æ–‡å­—é‡æ’å¤±æ•—")
            return None
    
    def _stage4_translate(self, image_path: Path, stage3_result: dict) -> dict:
        """éšæ®µ4: æ–‡å­—ç¿»è­¯"""
        reordered_texts = stage3_result['reordered_texts']
        
        # æº–å‚™æ–‡å­—åˆ—è¡¨å’Œå°æ‡‰çš„bboxä¿¡æ¯
        texts_to_translate = []
        bbox_mapping = []
        
        for item in reordered_texts:
            if isinstance(item, dict):
                text = item.get('text', '')
                bbox = item.get('bbox', [])
                if text and bbox:
                    texts_to_translate.append(text)
                    bbox_mapping.append(bbox)
            elif isinstance(item, str):
                texts_to_translate.append(item)
                bbox_mapping.append([0, 0, 100, 50])  # é»˜èªbbox
        
        if not texts_to_translate:
            print("   âš ï¸ æ²’æœ‰æ‰¾åˆ°éœ€è¦ç¿»è­¯çš„æ–‡å­—")
            return None
        
        # åŸ·è¡Œç¿»è­¯ï¼ˆå‚³éterminologyå’Œåœ–ç‰‡è·¯å¾‘ï¼‰
        translation_result = self.translator.translate_texts_with_history(
            texts_to_translate,
            terminology_dict=self.terminology_dict,
            translation_history=None,  # å¯ä»¥å¾ŒçºŒæ·»åŠ æ­·å²æ”¯æŒ
            image_path=str(image_path)
        )
        
        if not translation_result or not translation_result.get('translated_texts'):
            print("   âŒ ç¿»è­¯å¤±æ•—")
            return None
        
        # åˆä½µç¿»è­¯çµæœèˆ‡bboxä¿¡æ¯
        translated_texts = []
        translations = translation_result['translated_texts']
        
        for i, translation_item in enumerate(translations):
            # ç¢ºä¿æœ‰å°æ‡‰çš„bbox
            bbox = bbox_mapping[i] if i < len(bbox_mapping) else [0, 0, 100, 50]
            
            translated_item = {
                'original': translation_item.get('original', ''),
                'translated': translation_item.get('translated', ''),
                'bbox': bbox,
                'text_direction': translation_item.get('text_direction', 'horizontal'),
                'bubble_type': translation_item.get('bubble_type', 'pure_white'),
                'estimated_font_size': translation_item.get('estimated_font_size', 16)
            }
            translated_texts.append(translated_item)
        
        # æ§‹å»ºå®Œæ•´çµæœ
        result = {
            'translated_texts': translated_texts,
            'new_terminology': translation_result.get('new_terminology', {}),
            'total_texts': len(translated_texts),
            'source_image': str(image_path),
            'success': True
        }
        
        # ä¿å­˜æ–°ç™¼ç¾çš„å°ˆæœ‰åè©
        if translation_result.get('new_terminology'):
            self._save_terminology_dict(translation_result['new_terminology'])
        
        # ä¿å­˜çµæœ
        output_file = self.stage4_dir / f"{image_path.stem}_stage4_translate.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… ç¿»è­¯å®Œæˆ {len(result['translated_texts'])} æ®µæ–‡å­—")
        if translation_result.get('new_terminology'):
            print(f"   ğŸ“ ç™¼ç¾æ–°å°ˆæœ‰åè©: {len(translation_result['new_terminology'])} å€‹")
        print(f"   ğŸ’¾ çµæœä¿å­˜: {output_file.name}")
        return result


def main():
    """ä¸»å‡½å¼"""
    parser = argparse.ArgumentParser(description='æ¼«ç•«ç¿»è­¯å™¨')
    parser.add_argument('target', help='è¦ç¿»è­¯çš„åœ–ç‰‡è·¯å¾‘æˆ–è³‡æ–™å¤¾è·¯å¾‘')
    parser.add_argument('--output', '-o', default='output', help='è¼¸å‡ºç›®éŒ„ (é è¨­: output)')
    parser.add_argument('--batch', '-b', action='store_true', help='æ‰¹é‡ç¿»è­¯æ¨¡å¼')
    
    args = parser.parse_args()
    
    print("ğŸ¨ æ¼«ç•«ç¿»è­¯å™¨ - ç¿»è­¯æ¨¡å¼")
    print("=" * 70)
    
    # åˆå§‹åŒ–ç¿»è­¯å™¨
    translator = ComicTranslator(output_dir=args.output)
    
    # æ‰¹é‡ç¿»è­¯æ¨¡å¼
    if args.batch:
        translated_files = translator.batch_translate_folder(args.target)
        success = len(translated_files) > 0
        
        if success:
            print(f"\nğŸ‰ æ‰¹é‡ç¿»è­¯å®Œæˆï¼å…±ç¿»è­¯ {len(translated_files)} å¼µåœ–ç‰‡")
            print("ğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨ python run/render.py --batch æ‰¹é‡æ¸²æŸ“")
        else:
            print("\nâŒ æ‰¹é‡ç¿»è­¯å¤±æ•—")
    else:
        # å–®å¼µåœ–ç‰‡ç¿»è­¯
        success = translator.translate_image(args.target)
        
        if success:
            print("\nğŸ‰ ç¿»è­¯ä»»å‹™å®Œæˆï¼")
            print("ğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨ python run/render.py æ¸²æŸ“åœ–ç‰‡")
        else:
            print("\nâŒ ç¿»è­¯å¤±æ•—")
    
    return success


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 